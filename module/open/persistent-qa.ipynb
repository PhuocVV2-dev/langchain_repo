{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Question Answering with local persistence\n",
    "\n",
    "An example of using Chroma DB and LangChain to do question answering over documents, with a locally persisted database. \n",
    "You can store embeddings and documents, then use them again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process documents\n",
    "\n",
    "Load documents to do question answering over. If you want to do this over your documents, this is the section you should replace.\n",
    "\n",
    "Next we split documents into small chunks. This is so we can find the most relevant chunks for a query and pass only those into the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the text\n",
    "loader = TextLoader('../db/state_of_the_union.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize PeristedChromaDB\n",
    "\n",
    "Create embeddings for each chunk and insert into the Chroma vector database. The `persist_directory` argument tells ChromaDB where to store the database when it's persisted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/migration for more information or join our discord at https://discord.gg/8g5FESbj for help!\u001b[0m",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Embed and store the texts\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Supplying a persist_directory will store the embeddings on disk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m persist_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m client \u001b[39m=\u001b[39m chromadb\u001b[39m.\u001b[39;49mPersistentClient(path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../db/chroma_migrated\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m embedding \u001b[39m=\u001b[39m OpenAIEmbeddings(client\u001b[39m=\u001b[39mclient)\n",
      "File \u001b[0;32m~/miniconda3/envs/lc/lib/python3.10/site-packages/chromadb/__init__.py:73\u001b[0m, in \u001b[0;36mPersistentClient\u001b[0;34m(path, settings)\u001b[0m\n\u001b[1;32m     70\u001b[0m settings\u001b[39m.\u001b[39mpersist_directory \u001b[39m=\u001b[39m path\n\u001b[1;32m     71\u001b[0m settings\u001b[39m.\u001b[39mis_persistent \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m Client(settings)\n",
      "File \u001b[0;32m~/miniconda3/envs/lc/lib/python3.10/site-packages/chromadb/__init__.py:107\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mClient\u001b[39m(settings: Settings \u001b[39m=\u001b[39m __settings) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m API:\n\u001b[1;32m    105\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a running chroma.API instance\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m     system \u001b[39m=\u001b[39m System(settings)\n\u001b[1;32m    109\u001b[0m     telemetry_client \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39minstance(Telemetry)\n\u001b[1;32m    110\u001b[0m     api \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39minstance(API)\n",
      "File \u001b[0;32m~/miniconda3/envs/lc/lib/python3.10/site-packages/chromadb/config.py:175\u001b[0m, in \u001b[0;36mSystem.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39m# Validate settings don't contain any legacy config values\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m _legacy_config_keys:\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mif\u001b[39;00m settings[key] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettings \u001b[39m=\u001b[39m settings\n",
      "File \u001b[0;32m~/miniconda3/envs/lc/lib/python3.10/site-packages/chromadb/config.py:110\u001b[0m, in \u001b[0;36mSettings.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m# Error on legacy config values\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39min\u001b[39;00m _legacy_config_values:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(LEGACY_ERROR)\n\u001b[1;32m    111\u001b[0m \u001b[39mreturn\u001b[39;00m val\n",
      "\u001b[0;31mValueError\u001b[0m: \u001b[91mYou are using a deprecated configuration of Chroma.\n\n\u001b[94mIf you do not have data you wish to migrate, you only need to change how you construct\nyour Chroma client. Please see the \"New Clients\" section of https://docs.trychroma.com/migration.\n________________________________________________________________________________________________\n\nIf you do have data you wish to migrate, we have a migration tool you can use in order to\nmigrate your data to the new Chroma architecture.\nPlease `pip install chroma-migrate` and run `chroma-migrate` to migrate your data and then\nchange how you construct your Chroma client.\n\nSee https://docs.trychroma.com/migration for more information or join our discord at https://discord.gg/8g5FESbj for help!\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "client = chromadb.PersistentClient(path='../db/chroma_migrated')\n",
    "embedding = OpenAIEmbeddings(client=client)\n",
    "#vectordb = Chroma.from_documents(documents=texts, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist the Database\n",
    "In a notebook, we should call `persist()` to ensure the embeddings are written to disk.\n",
    "This isn't necessary in a script - the database will be automatically persisted when the client object is destroyed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Database from disk, and create the chain\n",
    "Be sure to pass the same `persist_directory` and `embedding_function` as you did when you instantiated the database. Initialize the chain we will use for question answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Chroma using direct local API.\n",
      "loaded in 82 embeddings\n",
      "loaded in 1 collections\n",
      "PersistentDuckDB del, about to run persist\n",
      "Persisting DB to disk, putting it in the save folder db\n"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=vectordb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions!\n",
    "\n",
    "Now we can use the chain to ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The president said that Ketanji Brown Jackson is one of our nation’s top legal minds and that she will continue Justice Breyer’s legacy of excellence. He also said she is a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. He mentioned that she is a consensus builder and has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "qa.run(query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "When you're done with the database, you can delete it from disk. You can delete the specific collection you're working with (if you have several), or delete the entire database by nuking the persistence directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisting DB to disk, putting it in the save folder db\n"
     ]
    }
   ],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "vectordb.delete_collection()\n",
    "vectordb.persist()\n",
    "\n",
    "# Or just nuke the persist directory\n",
    "!rm -rf db/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chroma-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c909e91d0cd7642213937968dfc91c71973575965f56cdcabb1e0b29abe5f7fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
